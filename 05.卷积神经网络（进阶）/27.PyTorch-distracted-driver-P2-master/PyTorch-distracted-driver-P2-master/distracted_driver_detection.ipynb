{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "distracted_driver_detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chengleniubi/L_tensor/blob/main/05.%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88%E8%BF%9B%E9%98%B6%EF%BC%89/27.PyTorch-distracted-driver-P2-master/PyTorch-distracted-driver-P2-master/distracted_driver_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqeyAyX_dRsL"
      },
      "source": [
        "## 驾驶员状态检测\n",
        "在这个项目中，需要通过驾驶员状态的图片推测出驾驶员处于什么样的状态，在运行该 notebook 之前，需要按照数据处理的指示将数据预处理好，如果你已经完成了前面的过程，我们正式进入到项目中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lSs9onXPdRsQ"
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# 导入所有的包\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from torchvision import transforms as tfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2pPZXUOdRsQ"
      },
      "source": [
        "首先我们可视化几张图片，来看看具体图片是什么样的"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-I9ets_idRsQ"
      },
      "source": [
        "from PIL import Image\n",
        "img1 = Image.open('./dataset/train/c0/img_12247.jpg')\n",
        "img2 = Image.open('./dataset/train/c1/img_100021.jpg')\n",
        "img3 = Image.open('./dataset/train/c2/img_100108.jpg')\n",
        "img4 = Image.open('./dataset/train/c3/img_100006.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "l_nqlND1dRsR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-DgEP49UdRsR"
      },
      "source": [
        "nrows = 2\n",
        "ncols = 2\n",
        "figsize = (10, 10)\n",
        "_, figs = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "figs[0, 0].imshow(img1)\n",
        "figs[0, 0].axes.set_xlabel('safe driving')\n",
        "figs[0, 0].axes.get_yaxis().set_visible(False)\n",
        "figs[0, 1].imshow(img2)\n",
        "figs[0, 1].axes.set_xlabel('texting right')\n",
        "figs[0, 1].axes.get_yaxis().set_visible(False)\n",
        "figs[1, 0].imshow(img3)\n",
        "figs[1, 0].axes.set_xlabel('talking on the phone right')\n",
        "figs[1, 0].axes.get_yaxis().set_visible(False)\n",
        "figs[1, 1].imshow(img4)\n",
        "figs[1, 1].axes.set_xlabel('texting left')\n",
        "figs[1, 1].axes.get_yaxis().set_visible(False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTrr85DTdRsR"
      },
      "source": [
        "上面从左往右，从上到下依次是：安全驾驶，右手发信息，右手打电话，左手发信息的图片，通过图片展示，相信你已经更好的理解了该项目。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUHU5apdRsS"
      },
      "source": [
        "### 数据预处理\n",
        "在数据传入图片中，我们需要进行数据预处理和数据增强的操作，相信在前面的课程中你已经了解到了这些内容，下面需要你实现一个数据的预处理\n",
        "\n",
        "常见的数据预处理：\n",
        " - resize\n",
        " - crop\n",
        " - normalize\n",
        " - ...\n",
        "\n",
        "等等"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "3AGCdHJ5dRsS"
      },
      "source": [
        "# 实现数据预处理\n",
        "\n",
        "train_transform = tfs.Compose([\n",
        "    # 训练集的数据预处理\n",
        "    # todo\n",
        "])\n",
        "\n",
        "test_transform = tfs.Compose([\n",
        "    # 测试集的数据预处理\n",
        "    # todo\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RtV71Q4SdRsS"
      },
      "source": [
        "# 每一个batch的数据集数目，可以自行修改，推荐使用2的次方\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "TfHiDTmtdRsS"
      },
      "source": [
        "# =======不要修改这里的内容========\n",
        "train_set = ImageFolder('./dataset/train', train_transform)\n",
        "train_data = DataLoader(train_set, batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "valid_set = ImageFolder('./dataset/valid', test_transform)\n",
        "valid_data = DataLoader(valid_set, 2 * batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "train_valid_set = ImageFolder('./dataset/train_valid/', train_transform)\n",
        "train_valid_data = DataLoader(train_valid_set, batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7kWN2qTJdRsS"
      },
      "source": [
        "# 测试\n",
        "# =======不要修改这里的内容========\n",
        "try:\n",
        "    if iter(train_data).next()[0].shape[0] == batch_size and \\\n",
        "    iter(test_data).next()[0].shape[0] == batch_size:\n",
        "        print('Success!')\n",
        "    else:\n",
        "        print('Not success, maybe the batch size is wrong!')\n",
        "except:\n",
        "    print('not success, image transform is wrong!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "sGKIehGddRsT"
      },
      "source": [
        "from torchvision import models\n",
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RTOurj0AdRsT"
      },
      "source": [
        "# 构建模型，推荐使用 torchvision.models 中的预训练模型，将最后的全连接层修改成10分类\n",
        "# 如果忘记了如何修改最后的全连接层，可以看看通过微调进行迁移学习的那个教程\n",
        "\n",
        "def get_model():\n",
        "    # todo\n",
        "    model = None\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okRsiIuMdRsT"
      },
      "source": [
        "构建好了模型之后，运行下面的代码对模型进行测试，看看模型是否构建正确"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6e9T1Yw6dRsT"
      },
      "source": [
        "# 测试\n",
        "# =======不要修改这里的内容========\n",
        "try:\n",
        "    model = get_model()\n",
        "    score = model(Variable(iter(train_data).next()[0], volatile=True))\n",
        "    if score.shape[0] == batch_size and score.shape[1] == 10:\n",
        "        print('successed!')\n",
        "    else:\n",
        "        print('failed!')\n",
        "except:\n",
        "    print('model is wrong!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZP5XWBjrdRsT"
      },
      "source": [
        "# 根据自己的情况修改是否使用GPU\n",
        "use_gpu = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7xZfYREpdRsU"
      },
      "source": [
        "# =======不要修改这里的内容========\n",
        "if use_gpu:\n",
        "    model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "YJnT8GV7dRsU"
      },
      "source": [
        "# 构建loss函数和优化器\n",
        "\n",
        "# todo\n",
        "criterion = None # 使用交叉熵作为loss函数\n",
        "optimzier = None # 可以使用前面讲过的多种优化方式"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b5G1yUbdRsU"
      },
      "source": [
        "当你构建好了前面的过程，我们就可以开始训练了，整个训练的框架已经写好，你只需要在需要的地方补充完整的代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JWgnknuJdRsU"
      },
      "source": [
        "# 训练的 epochs 数目\n",
        "max_epoch = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnSulBkgdRsU"
      },
      "source": [
        "下面是训练的代码，只需要填写其中的 **todo** 代码\n",
        "\n",
        "**注意: 如果你发现显存超过限制，可以改小 batch size**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KbJrmilPdRsU"
      },
      "source": [
        "def train(model, train_data, valid_data, max_epoch, criterion, optimizer):\n",
        "    # 开始训练\n",
        "    freq_print = int(len(train_data) / 3)\n",
        "\n",
        "    metric_log = dict()\n",
        "    metric_log['train_loss'] = list()\n",
        "    metric_log['train_acc'] = list()\n",
        "    if valid_data is not None:\n",
        "        metric_log['valid_loss'] = list()\n",
        "        metric_log['valid_acc'] = list()\n",
        "\n",
        "    for e in range(max_epoch):\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        running_acc = 0\n",
        "\n",
        "        for i, data in enumerate(train_data, 1):\n",
        "            img, label = data\n",
        "            if use_gpu:\n",
        "                img = img.cuda()\n",
        "                label = label.cuda()\n",
        "            img = Variable(img)\n",
        "            label = Variable(label)\n",
        "            \n",
        "            # 网络前向传播\n",
        "            # todo\n",
        "\n",
        "            # 计算误差\n",
        "            # todo\n",
        "            loss = None\n",
        "\n",
        "            # 反向传播，更新参数\n",
        "            # todo\n",
        "\n",
        "            # 计算准确率，是一个 Variable\n",
        "            # todo\n",
        "            acc = None\n",
        "\n",
        "            running_loss += loss.data[0]\n",
        "            running_acc += acc.data[0]\n",
        "\n",
        "            if i % freq_print == 0:\n",
        "                print('[{}]/[{}], train loss: {:.3f}, train acc: {:.3f}'.format(\n",
        "                    i, len(train_data), running_loss / i, running_acc / i))\n",
        "\n",
        "        metric_log['train_loss'].append(running_loss / len(train_data))\n",
        "        metric_log['train_acc'].append(running_acc / len(train_data))\n",
        "        \n",
        "        if valid_data is not None:\n",
        "            model.eval()\n",
        "            running_loss = 0\n",
        "            running_acc = 0\n",
        "            for data in valid_data:\n",
        "                img, label = data\n",
        "                if use_gpu:\n",
        "                    img = img.cuda()\n",
        "                    label = label.cuda()\n",
        "                img = Variable(img, volatile=True)\n",
        "                label = Variable(label, volatile=True)\n",
        "            \n",
        "                # 网络前向传播\n",
        "                # todo\n",
        "\n",
        "                # 计算误差\n",
        "                # todo\n",
        "                loss =None\n",
        "\n",
        "                # 计算准确率，结果是一个 Variable\n",
        "                # todo\n",
        "                acc = None\n",
        "\n",
        "                running_loss += loss.data[0]\n",
        "                running_acc += acc.data[0]\n",
        "\n",
        "            metric_log['valid_loss'].append(running_loss / len(valid_data))\n",
        "            metric_log['valid_acc'].append(running_acc / len(valid_data))\n",
        "            print_str = 'epoch: {}, train loss: {:.3f}, train acc: {:.3f}, \\\n",
        "            valid loss: {:.3f}, valid accuracy: {:.3f}'.format(\n",
        "                e + 1, metric_log['train_loss'][-1], metric_log['train_acc'][-1], \n",
        "                metric_log['valid_loss'][-1], metric_log['valid_acc'][-1])\n",
        "        \n",
        "        else:\n",
        "            print_str = 'epoch: {}, train loss: {:.3f}, train acc: {:.3f}'.format(\n",
        "                e + 1, \n",
        "                metric_log['train_loss'][-1],\n",
        "                metric_log['train_acc'][-1])\n",
        "        print(print_str)\n",
        "        print()\n",
        "    # =======不要修改这里的内容========\n",
        "    # 可视化\n",
        "    nrows = 1\n",
        "    ncols = 2\n",
        "    figsize= (10, 5)\n",
        "    _, figs = plt.subplots(nrows, ncols, figsize=figsize)\n",
        "    if valid_data is not None:\n",
        "        figs[0].plot(metric_log['train_loss'], label='train loss')\n",
        "        figs[0].plot(metric_log['valid_loss'], label='valid loss')\n",
        "        figs[0].axes.set_xlabel('loss')\n",
        "        figs[0].legend(loc='best')\n",
        "        figs[1].plot(metric_log['train_acc'], label='train acc')\n",
        "        figs[1].plot(metric_log['valid_acc'], label='valid acc')\n",
        "        figs[1].axes.set_xlabel('acc')\n",
        "        figs[1].legend(loc='best')\n",
        "    else:\n",
        "        figs[0].plot(metric_log['train_loss'], label='train loss')\n",
        "        figs[0].axes.set_xlabel('loss')\n",
        "        figs[0].legend(loc='best')\n",
        "        figs[1].plot(metric_log['train_acc'], label='train acc')\n",
        "        figs[1].axes.set_xlabel('acc')\n",
        "        figs[1].legend(loc='best')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DLKDPCb1dRsV"
      },
      "source": [
        "# 用作调参使用\n",
        "train(model, train_data, valid_data, max_epoch, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYITYk0dRsV"
      },
      "source": [
        "通过上面的结果，我们已经将模型跑起来了，那么你的下一个工作就是不断地调参，将验证集的准确率调高，具体的调参方式在课上已经讲过了，比如增加更多的数据增强，或者使用学习率衰减等等，可以通过输出的结果和画出的图像来判断最后模型的好坏\n",
        "\n",
        "**注意：可能在调参的过程中会出现显存超过限制，这是因为前面一个模型没有释放，所以最好每次调参都重新启动这个 notebook**\n",
        "\n",
        "当你调完参数之后，得到了一个最优的模型训练方式，那么可以重新训练模型，因为前面我们将数据集拆分成了训练集和验证集两个部分帮助我们调参，现在我们使用完整的数据集重新进行训练以便结果的提交"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "M2xiSLz5dRsV"
      },
      "source": [
        "# 完整的训练集\n",
        "train(model, train_valid_data, None, max_epoch, criterion, optimizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4YxLuYYdRsV"
      },
      "source": [
        "当运行完上面的代码之后，可以得到一个训练好的模型，那么我们保存模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nKq0w-E-dRsW"
      },
      "source": [
        "torch.save(model.state_dict(), './save_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1jTtygCdRsW"
      },
      "source": [
        "通过运行下面的程序能够使用你前面训练好的模型，对测试集进行预测，得到结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Pq9K-EpEdRsW"
      },
      "source": [
        "# =======不要修改这里的内容========\n",
        "from utils import TestSet, predict_result\n",
        "\n",
        "test_set = TestSet('./dataset/test', test_transform)\n",
        "test_data = DataLoader(test_set, 2*batch_size, num_workers=2)\n",
        "\n",
        "idx_to_class = dict()\n",
        "for i in train_set.class_to_idx:\n",
        "    idx_to_class[train_set.class_to_idx[i]] = i\n",
        "\n",
        "\n",
        "submission = predict_result(model, test_data, use_gpu)\n",
        "\n",
        "submission.columns = [['img'] + [i for i in idx_to_class.values()]]\n",
        "\n",
        "submission.to_csv('./submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzZOxKVvdRsW"
      },
      "source": [
        "通过运行上面的程序，我们能够在根目录下得到一个提交的csv文件，叫做`submission.csv`，最后只需要将这个文件提交到[kaggle的比赛界面](https://www.kaggle.com/c/state-farm-distracted-driver-detection/leaderboard)即可获得比赛的成绩。"
      ]
    }
  ]
}